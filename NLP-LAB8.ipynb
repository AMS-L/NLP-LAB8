{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP-LAB8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from bertopic import BERTopic\n",
    "import numpy as np\n",
    "from umap import UMAP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction (1 point)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. (1 point) Pick one of the datasets between hate and offensive, and justify your choice. Remember that it is for a commercial application (there is a good and a bad answer)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce contexte, le meilleur choix pour une application commerciale serait l'ensemble de données \"offensif\".\n",
    "\n",
    "Cet ensemble se concentre sur l'identification du langage offensant dans les tweets. Le langage offensant englobe un éventail plus large de contenus, y compris les jurons, les insultes et les remarques péjoratives. En utilisant cet ensemble de données, une application commerciale peut se concentrer sur la filtration et le signalement de contenus offensants afin de maintenir un environnement respectueux et inclusif pour les utilisateurs. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the dataset (5 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. (1 point) Describe the dataset. Look at the splits, proportion of classes, and see what you can figure out by just looking at the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_eval (/home/amine/.cache/huggingface/datasets/tweet_eval/offensive/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n",
      "100%|██████████| 3/3 [00:00<00:00, 1386.55it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('tweet_eval', 'offensive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available splits: dict_keys(['train', 'test', 'validation'])\n",
      "\n",
      "Number of offensive tweets: 3941\n",
      "Number of non-offensive tweets: 7975\n",
      "\n",
      "train : 11916 -> 84.51063829787235%\n",
      "test : 860 -> 6.0992907801418434%\n",
      "validation : 1324 -> 9.390070921985815%\n"
     ]
    }
   ],
   "source": [
    "splits = dataset.keys()\n",
    "print(\"Available splits:\", splits)\n",
    "print()\n",
    "\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "validation_data = dataset['validation']\n",
    "\n",
    "num_offensive = sum(1 for label in train_data['label'] if label == 1)\n",
    "num_non_offensive = len(train_data) - num_offensive\n",
    "\n",
    "print(\"Number of offensive tweets:\", num_offensive)\n",
    "print(\"Number of non-offensive tweets:\", num_non_offensive)\n",
    "print()\n",
    "\n",
    "total_examples = sum(len(dataset[s]) for s in dataset.keys())\n",
    "\n",
    "\n",
    "splits = dataset.keys()\n",
    "for split in splits:\n",
    "    num_examples = len(dataset[split])\n",
    "    print(f\"{split} : {num_examples} -> {(num_examples / total_examples) * 100 }%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample offensive tweets:\n",
      "@user Eight years the republicans denied obama’s picks. Breitbarters outrage is as phony as their fake president.\n",
      "@user She has become a parody unto herself? She has certainly taken some heat for being such an....well idiot. Could be optic too  Who know with Liberals  They're all optics.  No substance\n",
      "@user Your looking more like a plant #maga #walkaway\n",
      "@user Antifa would burn a Conservatives house down and CNN would be there lighting the torches &amp; throwing gas on the flames.\n",
      "@user They cite Jones being banned for violating Twitter's ToS. There are blue checkmarks spewing the same, if not worse, kind of shit. If you are going to play the anyone can get banned\"\" card. Shouldn't these people also receive bans and suspensions? #VerifiedHate\"\"\n",
      "\n",
      "Sample non-offensive tweets:\n",
      "@user Bono... who cares. Soon people will understand that they gain nothing from following a phony celebrity. Become a Leader of your people instead or help and support your fellow countrymen.\n",
      "@user Get him some line help. He is gonna be just fine. As the game went on you could see him progressing more with his reads. He brought what has been missing. The deep ball presence. Now he just needs a little more time\n",
      "@user @user She is great. Hi Fiona!\n",
      "@user @user @user @user @user @user @user @user @user @user @user @user @user @user @user This is the VetsResistSquadron\"\" is Bullshit.. They are girl scout veterans, I have never met any other veterans or served with anyone that was a gun control advocate? Have you?\"\"\n",
      "@user @user Lol. Except he’s the most successful president in our lifetimes. He’s undone most of the damage Obummer did and set America on the right path again. #MAGA\n"
     ]
    }
   ],
   "source": [
    "offensive_tweets = []\n",
    "non_offensive_tweets = []\n",
    "\n",
    "for example in train_data:\n",
    "    text = example['text']\n",
    "    label = example['label']\n",
    "    \n",
    "    if label == 1:\n",
    "        offensive_tweets.append(text)\n",
    "    else:\n",
    "        non_offensive_tweets.append(text)\n",
    "\n",
    "print(\"Sample offensive tweets:\")\n",
    "for tweet in offensive_tweets[:5]:\n",
    "    print(tweet)\n",
    "    \n",
    "print(\"\\nSample non-offensive tweets:\")\n",
    "for tweet in non_offensive_tweets[:5]:\n",
    "    print(tweet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que par catégories on a différentes sortes par situation : \n",
    "\n",
    "Pour les tweets offensive, on a : \n",
    "- Les attaques personnelles représenté par des insultes directes ou des language insultant.\n",
    "- Des point de vue politique discriminant et contribuant à divisée les débats politiques\n",
    "- Théorie du complot et la désinformation : des informations non étayées et infondées.\n",
    "\n",
    "Pour les tweets inoffensifs on a : \n",
    "- des conversations informelle étayant des sujets neutre tel que le sport\n",
    "- des opinions au ton neutres\n",
    "\n",
    "Globalement on peut voir que certains tweets sont plus subtiles dans la manière d'être offensant et qu'il faudra faire attention à cela."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. (3 points) Use BERTopic to extract the topics within the data, and the main topics within each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    processed_text = re.sub(r'@user', '', text)\n",
    "        \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_texts = [preprocess_text(text) for text in train_data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3527</td>\n",
       "      <td>-1_is_the_she_and</td>\n",
       "      <td>[is, the, she, and, to, he, you, of, that, are]</td>\n",
       "      <td>[    Nothing abusive should ever be done to an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1193</td>\n",
       "      <td>0_you_are_bitch_my</td>\n",
       "      <td>[you, are, bitch, my, love, so, shit, me, ass,...</td>\n",
       "      <td>[ Yes!  We were.  Back again.  Thank you so mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>975</td>\n",
       "      <td>1_antifa_they_the_of</td>\n",
       "      <td>[antifa, they, the, of, and, to, left, violenc...</td>\n",
       "      <td>[ Yes that and ANTIFA.,   That would be Antifa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>887</td>\n",
       "      <td>2_gun_control_guns_laws</td>\n",
       "      <td>[gun, control, guns, laws, the, to, about, in,...</td>\n",
       "      <td>[ Or we could have gun control,  GUN CONTROL W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>661</td>\n",
       "      <td>3_maga_trump_qanon_wwg1wga</td>\n",
       "      <td>[maga, trump, qanon, wwg1wga, walkaway, presid...</td>\n",
       "      <td>[ Thank you President Trump!! You are #MAGA!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>79_levi_rosie_runs_long</td>\n",
       "      <td>[levi, rosie, runs, long, she, bitxh, konjam, ...</td>\n",
       "      <td>[ because im a broke ass bitxh :(((( and LOL E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>80_her_mane_blonde_me</td>\n",
       "      <td>[her, mane, blonde, me, she, dead, hurts, drin...</td>\n",
       "      <td>[ His frustration began to subside as he felt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>81</td>\n",
       "      <td>11</td>\n",
       "      <td>81_she_tv_shame_5children</td>\n",
       "      <td>[she, tv, shame, 5children, iya, abortive, alp...</td>\n",
       "      <td>[ Iya Risi in my area didnt get the money. She...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>82_ect_represents_pro_all</td>\n",
       "      <td>[ect, represents, pro, all, traitor, choice, b...</td>\n",
       "      <td>[ Harley is the right choice for public educat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>83_meow_veronique_yeahhhhh_liker</td>\n",
       "      <td>[meow, veronique, yeahhhhh, liker, catfight, c...</td>\n",
       "      <td>[ CATFIGHT!!!   MEOW,  Yeahhhhh I will admit t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                              Name  \\\n",
       "0      -1   3527                 -1_is_the_she_and   \n",
       "1       0   1193                0_you_are_bitch_my   \n",
       "2       1    975              1_antifa_they_the_of   \n",
       "3       2    887           2_gun_control_guns_laws   \n",
       "4       3    661        3_maga_trump_qanon_wwg1wga   \n",
       "..    ...    ...                               ...   \n",
       "80     79     13           79_levi_rosie_runs_long   \n",
       "81     80     12             80_her_mane_blonde_me   \n",
       "82     81     11         81_she_tv_shame_5children   \n",
       "83     82     11         82_ect_represents_pro_all   \n",
       "84     83     11  83_meow_veronique_yeahhhhh_liker   \n",
       "\n",
       "                                       Representation  \\\n",
       "0     [is, the, she, and, to, he, you, of, that, are]   \n",
       "1   [you, are, bitch, my, love, so, shit, me, ass,...   \n",
       "2   [antifa, they, the, of, and, to, left, violenc...   \n",
       "3   [gun, control, guns, laws, the, to, about, in,...   \n",
       "4   [maga, trump, qanon, wwg1wga, walkaway, presid...   \n",
       "..                                                ...   \n",
       "80  [levi, rosie, runs, long, she, bitxh, konjam, ...   \n",
       "81  [her, mane, blonde, me, she, dead, hurts, drin...   \n",
       "82  [she, tv, shame, 5children, iya, abortive, alp...   \n",
       "83  [ect, represents, pro, all, traitor, choice, b...   \n",
       "84  [meow, veronique, yeahhhhh, liker, catfight, c...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [    Nothing abusive should ever be done to an...  \n",
       "1   [ Yes!  We were.  Back again.  Thank you so mu...  \n",
       "2   [ Yes that and ANTIFA.,   That would be Antifa...  \n",
       "3   [ Or we could have gun control,  GUN CONTROL W...  \n",
       "4   [ Thank you President Trump!! You are #MAGA!!!...  \n",
       "..                                                ...  \n",
       "80  [ because im a broke ass bitxh :(((( and LOL E...  \n",
       "81  [ His frustration began to subside as he felt ...  \n",
       "82  [ Iya Risi in my area didnt get the money. She...  \n",
       "83  [ Harley is the right choice for public educat...  \n",
       "84  [ CATFIGHT!!!   MEOW,  Yeahhhhh I will admit t...  \n",
       "\n",
       "[85 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "umap_model = UMAP(random_state=42)\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "topic_model = BERTopic(umap_model=umap_model, embedding_model=sentence_model)\n",
    "\n",
    "topics, _= topic_model.fit_transform(preprocessed_texts)\n",
    "\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: [('you', 0.03331236060163969), ('are', 0.026921978562256567), ('bitch', 0.016723565026909307), ('my', 0.016353993503892644), ('love', 0.014879897617191789), ('so', 0.014472967813977503), ('shit', 0.014283494713751921), ('me', 0.013565285987739793), ('ass', 0.013506062725468497), ('fuck', 0.013067996246574825)]\n",
      "Topic 1: [('antifa', 0.05910450011161495), ('they', 0.011723008805178783), ('the', 0.011689573428195573), ('of', 0.010606622773460082), ('and', 0.010462920126402788), ('to', 0.009671640220384612), ('left', 0.009285333501965668), ('violence', 0.009114582612419117), ('fascist', 0.008843518014682998), ('like', 0.008767320286951345)]\n",
      "Topic 2: [('gun', 0.05372058123253262), ('control', 0.049400412365636644), ('guns', 0.016262606249783637), ('laws', 0.01540265042564565), ('the', 0.010690881499212213), ('to', 0.009872345834673247), ('about', 0.009582369320340876), ('in', 0.009453942192125914), ('nra', 0.00917008038487963), ('that', 0.009047538851918134)]\n",
      "Topic 3: [('maga', 0.07230746045815623), ('trump', 0.020016137597911772), ('qanon', 0.018162181246683878), ('wwg1wga', 0.016412041123876005), ('walkaway', 0.012774064655848745), ('president', 0.012340091718387732), ('kag', 0.010960802624164651), ('america', 0.010563897750797349), ('we', 0.0097500885459237), ('to', 0.009356977770274744)]\n",
      "Topic 4: [('he', 0.06293771775756164), ('is', 0.028820354623986535), ('him', 0.024442106581473718), ('his', 0.01871029138316113), ('so', 0.011156771228380854), ('man', 0.010941388041020473), ('in', 0.008518215053537847), ('yes', 0.00838497876865244), ('was', 0.00811060550474986), ('to', 0.00810722046786459)]\n",
      "Topic 5: [('liberals', 0.04095152262864591), ('conservatives', 0.024476993762975248), ('they', 0.016338772648561043), ('are', 0.012653975173358176), ('the', 0.011834817360781598), ('their', 0.011042317129544638), ('that', 0.010794696764910263), ('and', 0.010493472404156032), ('of', 0.010471137142895307), ('to', 0.010385120622311967)]\n",
      "Topic 6: [('she', 0.06315531850027671), ('her', 0.031267140859785096), ('is', 0.026414705894094056), ('but', 0.010161292368547284), ('so', 0.009690152071285985), ('me', 0.009481074735979738), ('that', 0.00921433177366021), ('to', 0.009037276846592139), ('and', 0.008774196265824296), ('who', 0.00825245329301212)]\n",
      "Topic 7: [('kavanaugh', 0.07203403775876376), ('judge', 0.0225630860769712), ('maga', 0.016167555265241662), ('this', 0.011512503893330195), ('to', 0.01104558145556493), ('liberals', 0.010750217888316399), ('confirm', 0.010584036377551648), ('will', 0.010578747972399955), ('accuser', 0.010498747491603226), ('vote', 0.010003538080393786)]\n",
      "Topic 8: [('brexit', 0.04325263723877844), ('eu', 0.02719683803930925), ('uk', 0.027160567732940233), ('tories', 0.02557438393797076), ('tory', 0.019594712619875054), ('labour', 0.019010108789722008), ('the', 0.01699658709125982), ('conservatives', 0.016801091831268433), ('britain', 0.015405335967325849), ('party', 0.012324232359410348)]\n",
      "Topic 9: [('she', 0.042062628639383565), ('her', 0.03088144604855633), ('vote', 0.01719835839745389), ('is', 0.015120826655334343), ('the', 0.01157926677212674), ('to', 0.011447413440235678), ('democrat', 0.010798398286094517), ('and', 0.01002890187626616), ('by', 0.009657822558791903), ('president', 0.009171064274453345)]\n",
      "Topic 10: [('he', 0.04156201315354384), ('him', 0.022271000272841977), ('is', 0.019274718646639242), ('team', 0.015900837434998347), ('his', 0.014917281790812555), ('game', 0.012966544881561647), ('play', 0.012529700088925061), ('league', 0.01199210848755153), ('played', 0.011868399338829872), ('season', 0.011750771728101475)]\n",
      "Topic 11: [('holder', 0.10546616047560078), ('eric', 0.08519892247479201), ('prison', 0.03504627402225837), ('jail', 0.029418869492083964), ('should', 0.026086367504372165), ('furious', 0.019959573381331665), ('he', 0.017768174287766024), ('fast', 0.017273812545772326), ('be', 0.015896392368151303), ('in', 0.014784262669584158)]\n",
      "Topic 12: [('trudeau', 0.04523532336622797), ('canada', 0.0376876788306975), ('canadians', 0.02521099763003025), ('ontario', 0.022148377431117878), ('liberals', 0.02087709253147533), ('conservatives', 0.020435455607220866), ('ndp', 0.020250398630882644), ('cbc', 0.016579525093206107), ('bernier', 0.014740145411133049), ('the', 0.014403702544574579)]\n",
      "Topic 13: [('she', 0.08370686226207139), ('beautiful', 0.06300214105033462), ('cute', 0.05217396582791893), ('love', 0.03875514615827271), ('amazing', 0.03780128463020077), ('is', 0.03760224918469394), ('gorgeous', 0.03704709206813072), ('her', 0.027861791275972835), ('stunning', 0.027468122394036308), ('so', 0.02434725861477672)]\n",
      "Topic 14: [('pope', 0.08259559876581513), ('church', 0.035832908759117287), ('satan', 0.031826120298141386), ('catholic', 0.03035524998794475), ('francis', 0.021694256276792622), ('holy', 0.02142279729966801), ('devil', 0.01814092107648222), ('pedophiles', 0.01685141222108653), ('demon', 0.016056613899768625), ('the', 0.0156889711192977)]\n",
      "Topic 15: [('moore', 0.03032751787066377), ('fbi', 0.019811169527382655), ('he', 0.018302786933035376), ('trump', 0.016154507678605583), ('michael', 0.014975382161204975), ('fisa', 0.014831388552751111), ('to', 0.014060977175095954), ('had', 0.013340221264475847), ('released', 0.013104297165803065), ('ago', 0.012503505800172081)]\n",
      "Topic 16: [('blocked', 0.04457828869505638), ('block', 0.026357127870370766), ('you', 0.02170439399571551), ('shit', 0.020451096452586776), ('me', 0.019935390082195407), ('wall', 0.018440545121095), ('tweet', 0.01787223632795279), ('are', 0.015075691327361595), ('your', 0.013899167875939781), ('twitter', 0.013593089463044269)]\n",
      "Topic 17: [('nfl', 0.14934076923458928), ('football', 0.06384833704999093), ('players', 0.03493702099964948), ('watch', 0.028396561654536242), ('watching', 0.028073965137158947), ('baaaaa', 0.02678251584565527), ('league', 0.02546753984419575), ('goodell', 0.023442866067975257), ('boycott', 0.02226002285475866), ('the', 0.019050079674267067)]\n",
      "Topic 18: [('serena', 0.06799787186153236), ('tennis', 0.04324418770711267), ('she', 0.03585194619131221), ('her', 0.03450895306563598), ('williams', 0.028009122399989986), ('warning', 0.020448230637029795), ('was', 0.018879450142776286), ('rules', 0.0178889893449272), ('match', 0.01659693669574437), ('ref', 0.015699993547715257)]\n",
      "Topic 19: [('chicago', 0.13270593382252277), ('gun', 0.05530439901812053), ('control', 0.043861072225450506), ('laws', 0.03852387528951123), ('strictest', 0.027997851740216784), ('guns', 0.027346285991322942), ('strict', 0.02620848617210536), ('has', 0.021621042634963127), ('violence', 0.020497102479779494), ('rate', 0.018691138653755778)]\n",
      "Topic 20: [('guilty', 0.03753113046082875), ('innocent', 0.03299799459518008), ('proven', 0.03063633966780793), ('liberals', 0.028129068261872663), ('court', 0.025106249370285622), ('justice', 0.02330874521182289), ('until', 0.02302706080867651), ('conservatives', 0.015663704484482135), ('keith', 0.014893427333457087), ('ellison', 0.014436662408810383)]\n",
      "Topic 21: [('women', 0.072724137841612), ('conservatives', 0.019410088617172486), ('liberals', 0.015378030790742642), ('woman', 0.01453069279689497), ('the', 0.014460633103652342), ('accusers', 0.014322911235730157), ('of', 0.013941080716009325), ('political', 0.012729097083338463), ('years', 0.011897764362479907), ('were', 0.01181655785182003)]\n",
      "Topic 22: [('good', 0.16491264164772712), ('fuck', 0.15806248290275354), ('shit', 0.12208684851998772), ('yeah', 0.11683071744314122), ('oh', 0.1038180642971135), ('holy', 0.061378014485556756), ('doubt', 0.061378014485556756), ('nice', 0.05582994035043094), ('noes', 0.054675118436546814), ('nfw', 0.054675118436546814)]\n",
      "Topic 23: [('black', 0.04949058453585468), ('white', 0.039994045273409794), ('racist', 0.0369050641314929), ('race', 0.03366743898414796), ('people', 0.02029623594994026), ('color', 0.015151036199560822), ('racism', 0.014590209860186488), ('racial', 0.01409189653837967), ('it', 0.014073963162430536), ('are', 0.014002062689408052)]\n",
      "Topic 24: [('user', 0.07852016125568982), ('conservatives', 0.022411066009162296), ('prolife', 0.0167388990029472), ('republicans', 0.016541809414961226), ('democrats', 0.014757262127259465), ('antisemetic', 0.014375276494745935), ('bipartisan', 0.014375276494745935), ('teaparty', 0.012989118045265246), ('party', 0.012586384449137544), ('wakeup', 0.012543145571046466)]\n",
      "Topic 25: [('kerry', 0.06158380932732484), ('iran', 0.048142108028832016), ('obama', 0.04426705540764536), ('conspiracy', 0.02078586530668604), ('president', 0.020413860269815287), ('doj', 0.016018573796429313), ('traitor', 0.015589398980014525), ('he', 0.015377016625311421), ('resign', 0.014581754493321039), ('iranians', 0.014433066551006221)]\n",
      "Topic 26: [('he', 0.03430371955209162), ('his', 0.020175391987263563), ('him', 0.019823342030295333), ('joe', 0.01855301308514226), ('is', 0.017218748657664387), ('like', 0.016880876024220795), ('guy', 0.01547521372561642), ('president', 0.015403279298634638), ('leaders', 0.015134372568376516), ('coward', 0.014971514322968059)]\n",
      "Topic 27: [('liberals', 0.04158935408141162), ('facts', 0.026401533237408025), ('watching', 0.018223863485451023), ('story', 0.01738810508183109), ('their', 0.015584584675074861), ('zero', 0.015331810785323067), ('truth', 0.01502800505242723), ('just', 0.014387216520001002), ('supporting', 0.014066273597483922), ('left', 0.013925460302400878)]\n",
      "Topic 28: [('twitter', 0.08164142147011344), ('conservatives', 0.03697313443356082), ('tweets', 0.021336788020762235), ('bias', 0.02028169982401677), ('why', 0.017650412448651395), ('media', 0.01709717816241091), ('censorship', 0.01670464214275618), ('banning', 0.01597285977709776), ('twittershouldbe', 0.014594411807165843), ('censor', 0.014594411807165843)]\n",
      "Topic 29: [('cnn', 0.0806773685062915), ('breitbart', 0.03740307994489796), ('fox', 0.03154867013524996), ('news', 0.031081345552412123), ('network', 0.026035517643863425), ('liberals', 0.01703691226811943), ('only', 0.015978145764828595), ('propaganda', 0.01592628509424197), ('stranahahn', 0.0157638871770046), ('of', 0.01555810325057755)]\n",
      "Topic 30: [('assault', 0.03423435571320718), ('sexual', 0.03225691337375609), ('rape', 0.025451875513754954), ('sex', 0.02380660987828132), ('victim', 0.020148924205733384), ('sexually', 0.019490691989910956), ('liberals', 0.018971854950781592), ('years', 0.01404007014798596), ('you', 0.013998042199022474), ('would', 0.013997099660622375)]\n",
      "Topic 31: [('abortion', 0.060224156145222994), ('gay', 0.038461198681373536), ('india', 0.038357364807942544), ('babies', 0.03565119775495023), ('ernie', 0.027838446682581664), ('bert', 0.027838446682581664), ('puppets', 0.02284829976267507), ('children', 0.02072621626836897), ('liberals', 0.017696221347844775), ('abortions', 0.017136224822006305)]\n",
      "Topic 32: [('her', 0.032470803843172816), ('she', 0.026454735117983134), ('kavanaugh', 0.024136225831014376), ('vote', 0.01722015538954958), ('collins', 0.015982948980025197), ('heard', 0.014687370342816322), ('from', 0.014587077804786408), ('badly', 0.012922843975227395), ('this', 0.012477810440800308), ('on', 0.012440409824014)]\n",
      "Topic 33: [('t800', 0.02976002675374696), ('jaws', 0.02849808695582719), ('pic', 0.02805352707975863), ('god', 0.02798710290795017), ('digital', 0.02751962465331351), ('superman', 0.02406642440479075), ('movie', 0.022428949590295833), ('oh', 0.021888435225160093), ('avatar', 0.021026209689972458), ('recovered', 0.021026209689972458)]\n",
      "Topic 34: [('nigga', 0.22702121775980924), ('niggas', 0.13349413071497498), ('nigger', 0.05377274675346342), ('lol', 0.0428669082954713), ('ehen', 0.03799180216468568), ('dey', 0.03584849783564228), ('blood', 0.028110195639236626), ('tomorrow', 0.025588793158473427), ('fool', 0.02262388934555996), ('me', 0.022263445840093512)]\n",
      "Topic 35: [('patriots', 0.24085161985737874), ('following', 0.10369101191429198), ('follow', 0.09050268161170782), ('maga', 0.06916120863464488), ('followed', 0.05946412480946291), ('all', 0.05331710163603736), ('thank', 0.05134423559703298), ('back', 0.0424511766467131), ('kag', 0.04071862058192278), ('please', 0.03601062098538235)]\n",
      "Topic 36: [('puerto', 0.10343252503498138), ('rico', 0.08346577038001922), ('rican', 0.03429176895046357), ('died', 0.030551481746825336), ('mayor', 0.02844463439135318), ('hurricane', 0.026287706280225854), ('government', 0.020755915949648183), ('supplies', 0.020054980191848572), ('people', 0.019244663899595334), ('gutierrez', 0.018852491661718433)]\n",
      "Topic 37: [('housing', 0.11223618047301111), ('affordable', 0.044498043571658326), ('associations', 0.04423851879350331), ('social', 0.04093749679895037), ('build', 0.03602345107624234), ('homes', 0.03440773683939146), ('ge2017', 0.030047800555380987), ('labour', 0.028805440999110934), ('conservatives', 0.028380680318150466), ('initiative', 0.027624784888614237)]\n",
      "Topic 38: [('right', 0.19798676124811862), ('correct', 0.19573815983715018), ('absolutely', 0.13349447245928864), ('wrong', 0.12303852484692741), ('are', 0.07872053760576525), ('you', 0.06181829807936321), ('hope', 0.04819395274285805), ('100', 0.047713889018358956), ('refering', 0.0474290184027876), ('whiff', 0.0474290184027876)]\n",
      "Topic 39: [('tax', 0.039581839548226756), ('aside', 0.019462546422505125), ('economic', 0.018640156362036128), ('from', 0.017209772683619267), ('the', 0.0165243430315579), ('healthcare', 0.016376252155497126), ('negotiate', 0.01571214575301005), ('flier', 0.01571214575301005), ('taxes', 0.015179198035889093), ('country', 0.014335389038962353)]\n",
      "Topic 40: [('democracy', 0.07126670429831446), ('republic', 0.048172525352449785), ('constitutional', 0.037792029576874046), ('vote', 0.03418368781909711), ('democratic', 0.03171404895645782), ('citizens', 0.030250476054273806), ('tax', 0.02378553671734336), ('business', 0.023320759319165236), ('we', 0.02286131872733677), ('mike', 0.022402502189218965)]\n",
      "Topic 41: [('google', 0.14059229213714175), ('stock', 0.031979314919206386), ('cfo', 0.027939496533562622), ('engine', 0.02636329218263187), ('goo', 0.02636329218263187), ('utah', 0.024378603940613655), ('common', 0.02181736326600696), ('badly', 0.021688923610822634), ('search', 0.02038559535754111), ('political', 0.019638470791998833)]\n",
      "Topic 42: [('evil', 0.07814164513637539), ('ringwraith', 0.04162580063261214), ('godless', 0.03761196790498545), ('lord', 0.030798996961250567), ('satan', 0.02960187936265131), ('what', 0.029081163615969387), ('man', 0.028618072560915503), ('jesus', 0.02726889077637173), ('brown', 0.02726889077637173), ('is', 0.025753258861898044)]\n",
      "Topic 43: [('her', 0.05681293050250325), ('antifa', 0.05647185847558879), ('reputation', 0.03229036249440291), ('she', 0.031886492441608946), ('allsup', 0.028664473489523327), ('scoundrel', 0.027047369624496567), ('clothes', 0.02590045694055884), ('or', 0.02526575660011453), ('house', 0.022664278520418395), ('cali', 0.022251710051822023)]\n",
      "Topic 44: [('bono', 0.3591686816719418), ('u2', 0.07472830247356314), ('nothing', 0.03949900582130281), ('asshole', 0.03852277946241225), ('his', 0.03385768553518721), ('tax', 0.029557027244345797), ('relevance', 0.028945650936995374), ('epiphany', 0.028945650936995374), ('countrymen', 0.028945650936995374), ('nono', 0.028945650936995374)]\n",
      "Topic 45: [('her', 0.04967413295245049), ('she', 0.04779396473671229), ('is', 0.01938236105443897), ('offensive', 0.019124337252439887), ('threatening', 0.01782312108222461), ('wants', 0.017780397812365113), ('maxine', 0.017227257318691576), ('white', 0.01534278938142232), ('women', 0.014378020769982127), ('kill', 0.013959896891976482)]\n",
      "Topic 46: [('flake', 0.19180721444000196), ('senate', 0.048452295595590174), ('deepstate', 0.04394179032610327), ('schiff4brains', 0.04068243971175974), ('melting', 0.03675957203178465), ('writer', 0.03549745729596436), ('potus', 0.03547956742805394), ('snow', 0.03446662782896452), ('rino', 0.03284100633323781), ('ny', 0.03104318766472537)]\n",
      "Topic 47: [('he', 0.05490730436118792), ('mechanical', 0.045590162597622816), ('engineering', 0.045590162597622816), ('either', 0.0342530620934651), ('as', 0.03359858693116095), ('him', 0.02829045493212422), ('ignorant', 0.028257709880070973), ('because', 0.02816681827213993), ('completely', 0.02635580892634061), ('dumb', 0.02552225844591129)]\n",
      "Topic 48: [('josh', 0.08608528035583356), ('na', 0.0820250606294784), ('butt', 0.06912302930290201), ('cat', 0.05258540913190016), ('he', 0.03765413833187415), ('dominique', 0.037137816296522366), ('fur', 0.037137816296522366), ('adoptive', 0.037137816296522366), ('leia', 0.037137816296522366), ('loli', 0.037137816296522366)]\n",
      "Topic 49: [('happy', 0.07075095005827428), ('현재', 0.0694601021367817), ('birthday', 0.06498484351314956), ('beautiful', 0.061614510744865306), ('my', 0.0421939065847511), ('you', 0.03697446986010693), ('are', 0.03292584469501369), ('cherish', 0.031842353033816384), ('eliza', 0.031842353033816384), ('believe_hyunjae_day', 0.031842353033816384)]\n",
      "Topic 50: [('hats', 0.1356400778482347), ('maga', 0.06474870433895324), ('wearing', 0.06323228570535157), ('hat', 0.06200828153875451), ('cap', 0.06082816711395834), ('jacket', 0.04055211140930556), ('wear', 0.031616142852675784), ('pic', 0.031004140769377256), ('woodwork', 0.025479666844215994), ('yetis', 0.025479666844215994)]\n",
      "Topic 51: [('blame', 0.046417502369873305), ('durbin', 0.039346658002080884), ('president', 0.0351820859730939), ('bigly', 0.03316605362182722), ('he', 0.030726240671121324), ('3000', 0.02996796518988448), ('almost', 0.027850501421923985), ('words', 0.02743824102903321), ('biden', 0.023882143164148505), ('trump', 0.023551375361273292)]\n",
      "Topic 52: [('he', 0.03702540503876308), ('blk', 0.026643601518091257), ('leader', 0.023652814987500256), ('genocide', 0.023247870919249385), ('gop', 0.019529374697912584), ('wants', 0.018901981347838978), ('resign', 0.017945387409838507), ('long', 0.017161991766084024), ('senator', 0.017159909715278455), ('is', 0.016483996859656447)]\n",
      "Topic 53: [('cancer', 0.04095432867356952), ('my', 0.04082225648620391), ('your', 0.03253230976111054), ('diagnosed', 0.028437428154952846), ('intense', 0.028437428154952846), ('pregnant', 0.025695304806376197), ('friend', 0.023526254189250254), ('therapist', 0.02348352135995998), ('ok', 0.020174589993040018), ('me', 0.019997423827854292)]\n",
      "Topic 54: [('texas', 0.14430124760523133), ('tell', 0.04475662186116302), ('texans', 0.04436049197308525), ('texan', 0.03663495208737547), ('us', 0.0327561147473919), ('liberals', 0.028281026013587465), ('plans', 0.02751270681921064), ('campaign', 0.022547025729388197), ('voting', 0.021815893297504246), ('race', 0.02129980833690993)]\n",
      "Topic 55: [('sister', 0.10313794639189922), ('my', 0.045074067736208055), ('she', 0.037348040058038094), ('sniffs', 0.03710827188178602), ('loves', 0.03501184019306728), ('her', 0.031520795328631376), ('saint', 0.03064387154206664), ('precious', 0.03064387154206664), ('written', 0.027868168147624217), ('tears', 0.027868168147624217)]\n",
      "Topic 56: [('metoo', 0.13708459438992085), ('movement', 0.08429223288426373), ('extension', 0.04491255349632767), ('weapon', 0.038084781188643176), ('using', 0.02481758177335792), ('women', 0.024607544507765106), ('of', 0.023368382609989347), ('fancy', 0.023254711339103906), ('lot', 0.022972918117778546), ('dresses', 0.022456276748163834)]\n",
      "Topic 57: [('feinstein', 0.10802355646497688), ('letter', 0.05058872287606148), ('domestic', 0.03035323372563689), ('abuse', 0.027544905927657178), ('imagined', 0.02714671323686188), ('character', 0.02620143787050845), ('she', 0.0238719855248746), ('deals', 0.022925199258677937), ('spy', 0.022925199258677937), ('this', 0.02185689808200241)]\n",
      "Topic 58: [('levi', 0.17608014448473625), ('levistrauss', 0.10488551399676271), ('jeans', 0.09001869558531192), ('takes', 0.06143556158492575), ('stand', 0.05930230224837418), ('levis', 0.0584083283701413), ('sanfrancisco', 0.0584083283701413), ('strauss', 0.0584083283701413), ('gun', 0.05214340124712733), ('control', 0.0489165789538629)]\n",
      "Topic 59: [('manga', 0.05354958301485222), ('series', 0.04540877757107456), ('steak', 0.04091424848504612), ('reading', 0.039207115258986534), ('love', 0.03913370680450737), ('thanks', 0.03846213221148528), ('read', 0.03788629075787108), ('online', 0.03378683272586835), ('con', 0.03235916982887183), ('books', 0.03027251838071637)]\n",
      "Topic 60: [('davido', 0.03779184531118734), ('tallest', 0.03565982153124416), ('france', 0.034147707703210475), ('tweeting', 0.02933712298937588), ('cash', 0.02883748748854751), ('further', 0.026259463982674338), ('he', 0.026258806994596446), ('better', 0.026101944271651033), ('demand', 0.0252112618361515), ('business', 0.02074320171020487)]\n",
      "Topic 61: [('guilty', 0.10963625154860596), ('innocent', 0.09764588757646223), ('proven', 0.049861573062586186), ('until', 0.04164137852041366), ('accused', 0.03842968179050809), ('false', 0.0319126180156998), ('penalties', 0.03187537269175199), ('jackoff', 0.03187537269175199), ('semetic', 0.03187537269175199), ('eloquent', 0.03187537269175199)]\n",
      "Topic 62: [('list', 0.14508906436751243), ('account', 0.12621405119286425), ('names', 0.12028619746246427), ('twitter', 0.1085610253062049), ('lists', 0.1048071080075301), ('profile', 0.09901406900145424), ('supporters', 0.09582185728613124), ('target', 0.07811817007208689), ('suspended', 0.07404219760573011), ('publicizing', 0.07011338514143457)]\n",
      "Topic 63: [('monuments', 0.04208301919836267), ('insist', 0.037784843551628804), ('money', 0.03484883012290477), ('liberals', 0.034429075146976046), ('market', 0.03299892531562561), ('workers', 0.03254098140924264), ('conservatives', 0.03041936812928415), ('business', 0.02447955481328525), ('partylite', 0.02445098464243087), ('duhh', 0.02445098464243087)]\n",
      "Topic 64: [('lying', 0.0769291418762821), ('she', 0.06641211634380458), ('bhagwad', 0.05698770324702852), ('gita', 0.05698770324702852), ('tearing', 0.05149257510801579), ('apart', 0.04216529345885494), ('sure', 0.032817404772294084), ('clearly', 0.0324061211239998), ('cows', 0.031242924820883894), ('challenging', 0.031242924820883894)]\n",
      "Topic 65: [('beto', 0.2122870289254485), ('cruz', 0.0800580459420967), ('texas', 0.07878285384575305), ('turnout', 0.037745772094353154), ('ted', 0.029187175525838806), ('polls', 0.027795532906451946), ('vote', 0.027586358494679244), ('illegals', 0.027496430205042544), ('borders', 0.026943074690537482), ('dangerous', 0.024286043825219268)]\n",
      "Topic 66: [('numbers', 0.05798866041714788), ('rian', 0.045018499116774885), ('garth', 0.045018499116774885), ('jake', 0.045018499116774885), ('johnson', 0.038140186907913716), ('tyler', 0.036341301679100144), ('ben', 0.03494704305944462), ('as', 0.0331772880354724), ('paul', 0.03241682755509813), ('asked', 0.028760078277751875)]\n",
      "Topic 67: [('stormy', 0.048169841699305875), ('her', 0.03379099111407297), ('republicans', 0.027465818734979944), ('conservatives', 0.02713306520118974), ('professor', 0.02679380557867855), ('liberals', 0.024567672459448832), ('she', 0.023179852241881932), ('race', 0.023128877750882806), ('christina', 0.021809465525935573), ('amateur', 0.021809465525935573)]\n",
      "Topic 68: [('nra', 0.17539922968311122), ('unethical', 0.16897006519732521), ('research', 0.1434255450263631), ('calls', 0.1424622505433614), ('blames', 0.10417307795717103), ('ruger', 0.1023742028225116), ('9mm', 0.09940130411457905), ('gauge', 0.09940130411457905), ('winchester', 0.08481130017790837), ('shotgun', 0.08481130017790837)]\n",
      "Topic 69: [('quran', 0.10428925629077704), ('books', 0.040046434491073285), ('bible', 0.03848988082957802), ('she', 0.038227166100134206), ('blasphemy', 0.036082666377515546), ('kind', 0.03514449288794018), ('hinduism', 0.03404706578359996), ('hindus', 0.03404706578359996), ('tearing', 0.03260333901311553), ('guts', 0.03148392569214929)]\n",
      "Topic 70: [('billionaires', 0.03953059428926597), ('liberals', 0.03695387399108762), ('money', 0.031170342498820378), ('they', 0.027021359274783868), ('why', 0.02701689798806907), ('left', 0.02639648363988433), ('public', 0.02397714346542557), ('want', 0.01946199028169804), ('truly', 0.01814742782943989), ('the', 0.018024454172612083)]\n",
      "Topic 71: [('nike', 0.2551648226412769), ('kaepernick', 0.12212976999929048), ('kabasele', 0.05147276422312254), ('watford', 0.05147276422312254), ('justdoit', 0.04856893255151535), ('boycottnike', 0.04650942267820781), ('buying', 0.03576557818428763), ('much', 0.03501572810565167), ('military', 0.031903865993628516), ('christian', 0.03146108729610545)]\n",
      "Topic 72: [('signal', 0.05678520736620281), ('benign', 0.04338640851435404), ('opted', 0.04093876792106581), ('gesture', 0.03675746109856337), ('white', 0.03541356823989925), ('bigot', 0.03502379225266752), ('supremacy', 0.03502379225266752), ('co', 0.03368008077330161), ('brainwashed', 0.0331064811046769), ('used', 0.03107377792913044)]\n",
      "Topic 73: [('disgrace', 0.36730629439396806), ('yhuuu', 0.08557844624850805), ('siri', 0.08557844624850805), ('kangaka', 0.08557844624850805), ('wigs', 0.08557844624850805), ('bnf', 0.08557844624850805), ('umdala', 0.08557844624850805), ('imploding', 0.08557844624850805), ('rezz', 0.08557844624850805), ('anc', 0.08557844624850805)]\n",
      "Topic 74: [('fuck', 0.5795624373100964), ('what', 0.2786944846530399), ('thw', 0.1458003158307915), ('joking', 0.11265481132985625), ('weren', 0.0998609358623201), ('wtf', 0.09045729760626682), ('eyes', 0.0878901055764398), ('actual', 0.08494874972780414), ('happened', 0.07369780840559187), ('seen', 0.06709683711340138)]\n",
      "Topic 75: [('kavanaugh', 0.059152038305554176), ('gun', 0.045107004772017824), ('shake', 0.038496398243956766), ('control', 0.03799769972308993), ('spin', 0.03293430464668451), ('federal', 0.02566208741423681), ('guns', 0.02492130080905668), ('hand', 0.023585454010787762), ('in', 0.022876858062310164), ('words', 0.022501436298430644)]\n",
      "Topic 76: [('she', 0.04802529074448678), ('hag', 0.036264902066290884), ('remember', 0.02541295657340532), ('or', 0.023973757683063222), ('herself', 0.022016893265792217), ('states', 0.022016893265792217), ('happened', 0.02009940229243415), ('california', 0.019905092550196592), ('false', 0.019905092550196592), ('expunged', 0.01988186124965339)]\n",
      "Topic 77: [('cdnpoli', 0.06240363750905133), ('rules', 0.053263023114089696), ('horwath', 0.046325487800810285), ('disgruntled', 0.04371203929636381), ('faux', 0.0404212981466949), ('leadership', 0.032944027032628075), ('useless', 0.0318426401406783), ('lack', 0.03090412741205668), ('join', 0.028713479394265665), ('organiser', 0.02539747437052497)]\n",
      "Topic 78: [('best', 0.35805297488930415), ('he', 0.10181986385659847), ('player', 0.0943795034340315), ('hybrid', 0.08033894953941573), ('memelord', 0.08033894953941573), ('barun', 0.08033894953941573), ('bron', 0.08033894953941573), ('kamara', 0.08033894953941573), ('dedication', 0.08033894953941573), ('sobti', 0.08033894953941573)]\n",
      "Topic 79: [('levi', 0.06546569474432501), ('rosie', 0.05790911188834523), ('runs', 0.04608966270568621), ('long', 0.039531254538116616), ('she', 0.0357603703389717), ('bitxh', 0.03364622673018266), ('konjam', 0.03364622673018266), ('gasps', 0.03364622673018266), ('aura', 0.03364622673018266), ('bolt', 0.03364622673018266)]\n",
      "Topic 80: [('her', 0.04788077333887211), ('mane', 0.039024188093073876), ('blonde', 0.03405055006922668), ('me', 0.032015803093960564), ('she', 0.031007633371983857), ('dead', 0.03085544439872178), ('hurts', 0.03029376830424683), ('drink', 0.028874059651172405), ('then', 0.024465007410925884), ('himself', 0.021628704640771525)]\n",
      "Topic 81: [('she', 0.04868611874513092), ('tv', 0.03535373634368069), ('shame', 0.032158045641848224), ('5children', 0.031492868219450965), ('iya', 0.031492868219450965), ('abortive', 0.031492868219450965), ('alp', 0.031492868219450965), ('ama', 0.031492868219450965), ('zina', 0.031492868219450965), ('cbb', 0.031492868219450965)]\n",
      "Topic 82: [('ect', 0.04755265304056685), ('represents', 0.04296731432854298), ('pro', 0.04147115000696371), ('all', 0.03575070556721048), ('traitor', 0.03424161586117981), ('choice', 0.02947410136497469), ('bs', 0.02704086928227798), ('he', 0.026432706378666623), ('business', 0.02610071738370149), ('urgency', 0.026070255148552123)]\n",
      "Topic 83: [('meow', 0.11247452935518201), ('veronique', 0.11247452935518201), ('yeahhhhh', 0.11247452935518201), ('liker', 0.11247452935518201), ('catfight', 0.11247452935518201), ('cayde', 0.11247452935518201), ('cornhole', 0.11247452935518201), ('ticats', 0.11247452935518201), ('cats', 0.09268663519442842), ('destiny', 0.09268663519442842)]\n"
     ]
    }
   ],
   "source": [
    "topic_freq = topic_model.get_topic_freq()\n",
    "\n",
    "for i in range(len(topic_freq)):\n",
    "    if i in topic_freq['Topic'].values:\n",
    "        terms = topic_model.get_topic(i)\n",
    "        first_term = terms\n",
    "        print(f\"Topic {i}: {first_term}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: ('antifa', 0.05910450011161495)\n",
      "Topic 2: ('gun', 0.05372058123253262)\n",
      "Topic 3: ('maga', 0.07230746045815623)\n",
      "Topic 4: ('he', 0.06293771775756164)\n",
      "Topic 5: ('liberals', 0.04095152262864591)\n",
      "Topic 6: ('she', 0.06315531850027671)\n",
      "Topic 7: ('kavanaugh', 0.07203403775876376)\n",
      "Topic 8: ('brexit', 0.04325263723877844)\n",
      "Topic 9: ('she', 0.042062628639383565)\n",
      "Topic 10: ('he', 0.04156201315354384)\n",
      "Topic 11: ('holder', 0.10546616047560078)\n",
      "Topic 12: ('trudeau', 0.04523532336622797)\n",
      "Topic 13: ('she', 0.08370686226207139)\n",
      "Topic 14: ('pope', 0.08259559876581513)\n",
      "Topic 15: ('moore', 0.03032751787066377)\n",
      "Topic 16: ('blocked', 0.04457828869505638)\n",
      "Topic 17: ('nfl', 0.14934076923458928)\n",
      "Topic 18: ('serena', 0.06799787186153236)\n",
      "Topic 19: ('chicago', 0.13270593382252277)\n",
      "Topic 20: ('guilty', 0.03753113046082875)\n",
      "Topic 21: ('women', 0.072724137841612)\n",
      "Topic 22: ('good', 0.16491264164772712)\n",
      "Topic 23: ('black', 0.04949058453585468)\n",
      "Topic 24: ('user', 0.07852016125568982)\n",
      "Topic 25: ('kerry', 0.06158380932732484)\n",
      "Topic 26: ('he', 0.03430371955209162)\n",
      "Topic 27: ('liberals', 0.04158935408141162)\n",
      "Topic 28: ('twitter', 0.08164142147011344)\n",
      "Topic 29: ('cnn', 0.0806773685062915)\n",
      "Topic 30: ('assault', 0.03423435571320718)\n",
      "Topic 31: ('abortion', 0.060224156145222994)\n",
      "Topic 32: ('her', 0.032470803843172816)\n",
      "Topic 33: ('t800', 0.02976002675374696)\n",
      "Topic 34: ('nigga', 0.22702121775980924)\n",
      "Topic 35: ('patriots', 0.24085161985737874)\n",
      "Topic 36: ('puerto', 0.10343252503498138)\n",
      "Topic 37: ('housing', 0.11223618047301111)\n",
      "Topic 38: ('right', 0.19798676124811862)\n",
      "Topic 39: ('tax', 0.039581839548226756)\n",
      "Topic 40: ('democracy', 0.07126670429831446)\n",
      "Topic 41: ('google', 0.14059229213714175)\n",
      "Topic 42: ('evil', 0.07814164513637539)\n",
      "Topic 43: ('her', 0.05681293050250325)\n",
      "Topic 44: ('bono', 0.3591686816719418)\n",
      "Topic 45: ('her', 0.04967413295245049)\n",
      "Topic 46: ('flake', 0.19180721444000196)\n",
      "Topic 47: ('he', 0.05490730436118792)\n",
      "Topic 48: ('josh', 0.08608528035583356)\n",
      "Topic 49: ('happy', 0.07075095005827428)\n",
      "Topic 50: ('hats', 0.1356400778482347)\n",
      "Topic 51: ('blame', 0.046417502369873305)\n",
      "Topic 52: ('he', 0.03702540503876308)\n",
      "Topic 53: ('cancer', 0.04095432867356952)\n",
      "Topic 54: ('texas', 0.14430124760523133)\n",
      "Topic 55: ('sister', 0.10313794639189922)\n",
      "Topic 56: ('metoo', 0.13708459438992085)\n",
      "Topic 57: ('feinstein', 0.10802355646497688)\n",
      "Topic 58: ('levi', 0.17608014448473625)\n",
      "Topic 59: ('manga', 0.05354958301485222)\n",
      "Topic 60: ('davido', 0.03779184531118734)\n",
      "Topic 61: ('guilty', 0.10963625154860596)\n",
      "Topic 62: ('list', 0.14508906436751243)\n",
      "Topic 63: ('monuments', 0.04208301919836267)\n",
      "Topic 64: ('lying', 0.0769291418762821)\n",
      "Topic 65: ('beto', 0.2122870289254485)\n",
      "Topic 66: ('numbers', 0.05798866041714788)\n",
      "Topic 67: ('stormy', 0.048169841699305875)\n",
      "Topic 68: ('nra', 0.17539922968311122)\n",
      "Topic 69: ('quran', 0.10428925629077704)\n",
      "Topic 70: ('billionaires', 0.03953059428926597)\n",
      "Topic 71: ('nike', 0.2551648226412769)\n",
      "Topic 72: ('signal', 0.05678520736620281)\n",
      "Topic 73: ('disgrace', 0.36730629439396806)\n",
      "Topic 74: ('fuck', 0.5795624373100964)\n",
      "Topic 75: ('kavanaugh', 0.059152038305554176)\n",
      "Topic 76: ('she', 0.04802529074448678)\n",
      "Topic 77: ('cdnpoli', 0.06240363750905133)\n",
      "Topic 78: ('best', 0.35805297488930415)\n",
      "Topic 79: ('levi', 0.06546569474432501)\n",
      "Topic 80: ('her', 0.04788077333887211)\n",
      "Topic 81: ('she', 0.04868611874513092)\n",
      "Topic 82: ('ect', 0.04755265304056685)\n",
      "Topic 83: ('meow', 0.11247452935518201)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(topic_freq)):\n",
    "    if i in topic_freq['Topic'].values and  i != 0:\n",
    "        terms = topic_model.get_topic(i)\n",
    "        first_term = terms[0]\n",
    "        print(f\"Topic {i}: {first_term}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. (1 point) What do you think about the results? How do you think it could impact a model trained on these data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que les topics sont globalement diversifié et beaucoup sont des sujets de controverses.\n",
    "\n",
    "Il faudra faire attention à la nuance entre un sujet sensible et un contenu offensant. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les différents topics peuvent impacter le modèle en apportant un biais d'interprétation. Le modèle risque d'avoir un point de vue baser les datas et considérer les informations par expérience et de ce fait risque de rater certains tweets offensifs.\n",
    "\n",
    "On peut deviner qu'il y aura des nuances de contexte à prendre en compte pour les propos controversé."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. Bonus By default, BERTopic extracts single keywords. Play with the model to extract bigrams or more. See if you can go deeper in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "umap_model = UMAP(random_state=42)\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vectorizer_model = CountVectorizer(ngram_range=(5,5))\n",
    "\n",
    "topic_model = BERTopic(umap_model=umap_model, vectorizer_model=vectorizer_model, embedding_model=sentence_model)\n",
    "\n",
    "topics, _= topic_model.fit_transform(preprocessed_texts)\n",
    "\n",
    "topic_info = topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: ('kkk hoods beating up strangers', 0.0018539697359027949)\n",
      "Topic 2: ('to talk about gun control', 0.001397272481626641)\n",
      "Topic 3: ('zombie marketing sales retail style', 0.0013424828049194816)\n",
      "Topic 4: ('he is yes he is', 0.0035961423777717714)\n",
      "Topic 5: ('me give me give me', 0.0030617749254221536)\n",
      "Topic 6: ('yes she is she is', 0.0034817723102017356)\n",
      "Topic 7: ('not going to work and', 0.002902922280350557)\n",
      "Topic 8: ('remain london cityoflondon news breakingnews', 0.0035216712285047473)\n",
      "Topic 9: ('think she is one of', 0.003993839665817484)\n",
      "Topic 10: ('as good as he is', 0.004990564337370127)\n",
      "Topic 11: ('holder should be in prison', 0.013273369421415812)\n",
      "Topic 12: ('people party of canada liberal', 0.0055265025398821615)\n",
      "Topic 13: ('croatian president bikini photos worlds', 0.01744575163865596)\n",
      "Topic 14: ('the homosexual rot in the', 0.009970731665704067)\n",
      "Topic 15: ('michael moore and what he', 0.007196919097049552)\n",
      "Topic 16: ('also don even know who', 0.012188330728874241)\n",
      "Topic 17: ('11th stories and how we', 0.008157194470801704)\n",
      "Topic 18: ('williams is out of order', 0.007794708794035753)\n",
      "Topic 19: ('chicago has the strictest gun', 0.01361120467795553)\n",
      "Topic 20: ('if he had not been', 0.010746896406148097)\n",
      "Topic 21: ('for personal and political gain', 0.009075760808226205)\n",
      "Topic 22: ('absolutely nfw fuck yeah god', 0.056226376173740315)\n",
      "Topic 23: ('are part of the problem', 0.00842517768830332)\n",
      "Topic 24: ('laughs at conservatives on the', 0.014430003616697345)\n",
      "Topic 25: ('you are part of the', 0.012641330257171828)\n",
      "Topic 26: ('3ph so he can get', 0.00799156615667375)\n",
      "Topic 27: ('11th hour from lefty liberal', 0.009271722808390628)\n",
      "Topic 28: ('10 kevin williamson excellent piece', 0.008032339453391475)\n",
      "Topic 29: ('the only people still watching', 0.01583004806903402)\n",
      "Topic 30: ('100 proof they were violated', 0.005874397510689287)\n",
      "Topic 31: ('1000 gay children have now', 0.007419125979569881)\n",
      "Topic 32: ('in 1982 when was 18', 0.011130119068692912)\n",
      "Topic 33: ('100 page giants at walmart', 0.01159306725231759)\n",
      "Topic 34: ('about to lose don mess', 0.021047306589100652)\n",
      "Topic 35: ('all patriots please follow back', 0.03791329959736494)\n",
      "Topic 36: ('people died in puerto rico', 0.016260309851204822)\n",
      "Topic 37: ('tories labour ge2017 conservatives conservatives', 0.030146094944259773)\n",
      "Topic 38: ('you are right you are', 0.08862872591736948)\n",
      "Topic 39: ('10 20 books on the', 0.008650211719036972)\n",
      "Topic 40: ('2nd highest prop tax in', 0.015649488398257742)\n",
      "Topic 41: ('2018 midterms maga 2a prolife', 0.015434691498673813)\n",
      "Topic 42: ('13 million penthouse in new', 0.023084142710626525)\n",
      "Topic 43: ('2016 as well as helping', 0.015838415823588824)\n",
      "Topic 44: ('90s are over you sick', 0.029371987553446433)\n",
      "Topic 45: ('13 year old canadian girl', 0.01383425775803804)\n",
      "Topic 46: ('5th was the ny times', 0.022554993307517604)\n",
      "Topic 47: ('1977 he worked for boeing', 0.025310908888500464)\n",
      "Topic 48: ('about kyle since he is', 0.037844676270786755)\n",
      "Topic 49: ('because you are my 현재', 0.05804511690296048)\n",
      "Topic 50: ('about ncaa it is maga', 0.025808828407618507)\n",
      "Topic 51: ('16year pdp but you are', 0.018348933949472363)\n",
      "Topic 52: ('the fact that he is', 0.02424875444450779)\n",
      "Topic 53: ('2015 and she is doing', 0.015711961405835615)\n",
      "Topic 54: ('11 21 political corruption texans', 0.020287867691555786)\n",
      "Topic 55: ('11 months clear now and', 0.020552722361158342)\n",
      "Topic 56: ('benefit poster child for using', 0.02591670324659541)\n",
      "Topic 57: ('10 years she needs to', 0.016606946549206)\n",
      "Topic 58: ('takes stand on gun control', 0.05907421100054537)\n",
      "Topic 59: ('2018 read the best of', 0.022684993268944218)\n",
      "Topic 60: ('11 my building was the', 0.02093535283064799)\n",
      "Topic 61: ('about eric trump made anit', 0.03239379697252529)\n",
      "Topic 62: ('publicizing an antifa target list', 0.044126134788475053)\n",
      "Topic 63: ('10 years much to the', 0.024753750516741023)\n",
      "Topic 64: ('about developing next gen girls', 0.03174069622711147)\n",
      "Topic 65: ('100 and you all should', 0.022173782153024353)\n",
      "Topic 66: ('1st word rian johnson used', 0.024989500521662364)\n",
      "Topic 67: ('about her and ignore her', 0.02204955928381973)\n",
      "Topic 68: ('calls gun control research unethical', 0.1845209996041804)\n",
      "Topic 69: ('is your kind of woman', 0.03644125278836004)\n",
      "Topic 70: ('10yrs ago now the statue', 0.017649535121801892)\n",
      "Topic 71: ('then now not so much', 0.0522103767222322)\n",
      "Topic 72: ('absolutely insane liberals have been', 0.024072454630959157)\n",
      "Topic 73: ('about either one of them', 0.08945105300367778)\n",
      "Topic 74: ('what the fuck what the', 0.5189233451124666)\n",
      "Topic 75: ('187 which is why it', 0.02261980650667714)\n",
      "Topic 76: ('it happened she can remember', 0.036627177547484326)\n",
      "Topic 77: ('rules are for other people', 0.046921090191548546)\n",
      "Topic 78: ('he is the best he', 0.21618647429986815)\n",
      "Topic 79: ('admire the woman physique if', 0.03422475071445063)\n",
      "Topic 80: ('16 21 year olds if', 0.02162552929759243)\n",
      "Topic 81: ('5children and all attempt to', 0.0319987506679823)\n",
      "Topic 82: ('about illegal border crossers as', 0.02641507605477733)\n",
      "Topic 83: ('about you big don get', 0.11926807067157037)\n"
     ]
    }
   ],
   "source": [
    "topic_freq = topic_model.get_topic_freq()\n",
    "\n",
    "for i in range(len(topic_freq)):\n",
    "    if i in topic_freq['Topic'].values and  i != 0:\n",
    "        terms = topic_model.get_topic(i)\n",
    "        first_term = terms[0]\n",
    "        print(f\"Topic {i}: {first_term}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut remarquer qu'en augmentant le nombre de mots par topics on comprends mieux le sujet en lui même. Le sujet est beaucoup plus clair. plus on augmente le gram et moins il y a d'article tel que \"you\" \"she\" seul qui n'ont pas beaucoup de sens comme titre. \n",
    "\n",
    "Les mots sans sens seul sont rattaché à des contextes et permettent de mieux comprendre le topics à la lecture. \n",
    "\n",
    "A partir de (5,5) grams on  a déjà une compréhension claire de quasi tous les topics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a model (6 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. (2 points) Evaluate their model on the test split of the dataset you picked, using precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "import torch as torch\n",
    "\n",
    "task='offensive'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8556\n",
      "Recall: 0.8593\n",
      "F1-score: 0.8552\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "labels=[]\n",
    "text_test = test_data['text']\n",
    "true_labels = test_data['label']\n",
    "predictions = []\n",
    "\n",
    "# Pour la question 2\n",
    "\n",
    "# Pour les offensives\n",
    "misclassified_scores = []\n",
    "misclassified_texts = []\n",
    "misclassified_labels = []\n",
    "misclassified_true_labels = []\n",
    "\n",
    "# Pour les non offensives\n",
    "misclassified_scores_NO = []\n",
    "misclassified_texts_NO = []\n",
    "misclassified_labels_NO = []\n",
    "misclassified_true_labels_NO = []\n",
    "\n",
    "for text, true_label in zip(text_test, true_labels):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = torch.nn.functional.softmax(output.logits, dim=1).detach().cpu().numpy()\n",
    "    _, predicted = torch.max(output.logits, 1)\n",
    "\n",
    "    if predicted != true_label and true_label == 1:\n",
    "\n",
    "        misclassified_scores.append(scores[0][predicted[0]])\n",
    "        misclassified_texts.append(text)\n",
    "        misclassified_labels.append(predicted[0])\n",
    "        misclassified_true_labels.append(true_label)\n",
    "\n",
    "    if predicted != true_label and true_label == 0:\n",
    "\n",
    "        misclassified_scores_NO.append(scores[0][predicted[0]])\n",
    "        misclassified_texts_NO.append(text)\n",
    "        misclassified_labels_NO.append(predicted[0])\n",
    "        misclassified_true_labels_NO.append(true_label)\n",
    "\n",
    "    predictions.append(predicted.detach().cpu().numpy().flatten())\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average=\"weighted\")\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. (2 points) Look for prediction failures. Extract the top 5 misclassified tweets (highest score in wrong class) for each class and discuss what could be wrong with the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text : #Liberals / #Democrats THIS is what you stand for. If not, then #WalkAway\n",
      "Label : 0\n",
      "True Label : 1\n",
      "Score : 0.9338217973709106\n",
      "Text : #Liberals Are Reaching Peak Desperation To Call On #PhillipRuddock To Talk With #Turnbull To Convince Him To Help with #WentworthVotes 18 Sept 2018  @user #Auspol #LNP #NSWpol @user  @user @user #LNPMemes\n",
      "Label : 0\n",
      "True Label : 1\n",
      "Score : 0.9197562336921692\n",
      "Text : #NoPasaran: Unity demo to oppose the far-right in #London – #antifa #Oct13 — Enough is Enough!\n",
      "Label : 0\n",
      "True Label : 1\n",
      "Score : 0.9112220406532288\n",
      "Text : #BREXIT deal HAS been reached - and will be unveiled at special summit in NOVEMBER, Has @user sold out the #UK to the eu??? She better have not or the @user are finished!! @user\n",
      "Label : 0\n",
      "True Label : 1\n",
      "Score : 0.9081718325614929\n",
      "Text : #America  ... tear down that #Wall! #tcot #partisanship #Trump #thewall #Borderwall #liberty #civilsociety #think #Conservatives #Democrats #Progressives #liberals #Independent #libertarians #GOP #DNC #CriticalThinking\n",
      "Label : 0\n",
      "True Label : 1\n",
      "Score : 0.895766019821167\n"
     ]
    }
   ],
   "source": [
    "misclassified_scores = np.array(misclassified_scores)\n",
    "misclassified_texts = np.array(misclassified_texts)\n",
    "misclassified_labels = np.array(misclassified_labels)\n",
    "misclassified_true_labels = np.array(misclassified_true_labels)\n",
    "\n",
    "sorted_indices = np.argsort(misclassified_scores)[::-1]\n",
    "#sorted_indices\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Text : {misclassified_texts[sorted_indices[i]]}\")\n",
    "    print(f\"Label : {misclassified_labels[sorted_indices[i]]}\")\n",
    "    print(f\"True Label : {misclassified_true_labels[sorted_indices[i]]}\")\n",
    "    print(f\"Score : {misclassified_scores[sorted_indices[i]]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces erreurs soulignent comment ce modèle de peut avoir du mal à comprendre les nuances du langage et du contexte humains, en particulier dans les discussions politiques où le ton et l'intention peuvent être subtils ou sujets à interprétation.\n",
    "\n",
    "Par exemple : \"#Liberals Are Reaching Peak Desperation To Call On #PhillipRuddock To Talk With #Turnbull To Convince Him To Help with #WentworthVotes 18 Sept 2018 @user #Auspol #LNP #NSWpol @user @user @user #LNPMemes\"\n",
    "\n",
    "Cette phrase semble être une déclaration politique critique, mais elle n'utilise pas de langage explicitement offensant. Le modèle peut avoir du mal à saisir la complexité de cette déclaration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non Offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text : Are you fucking serious?\n",
      "Label : 1\n",
      "True Label : 0\n",
      "Score : 0.9010689854621887\n",
      "Text : @user I guess that’s where swamp ass originated\n",
      "Label : 1\n",
      "True Label : 0\n",
      "Score : 0.8939997553825378\n",
      "Text : An American Tail really is one of the most underrated animations ever ever ever. Fuck I cried in this scene\n",
      "Label : 1\n",
      "True Label : 0\n",
      "Score : 0.8576400279998779\n",
      "Text : @user @user Bull crap. You know she doesn't care.  She is trying to get attention for her Presidential run.  Do you see any other Senator giving nonsense?  Nope.\n",
      "Label : 1\n",
      "True Label : 0\n",
      "Score : 0.8492955565452576\n",
      "Text : #Room25 is actually incredible, Noname is the shit, always has been,  and I’m seein her in like 5 days in Melbourne. Life is good. Have a nice day.\n",
      "Label : 1\n",
      "True Label : 0\n",
      "Score : 0.8418040871620178\n"
     ]
    }
   ],
   "source": [
    "misclassified_scores_NO = np.array(misclassified_scores_NO)\n",
    "misclassified_texts_NO = np.array(misclassified_texts_NO)\n",
    "misclassified_labels_NO = np.array(misclassified_labels_NO)\n",
    "misclassified_true_labels_NO = np.array(misclassified_true_labels_NO)\n",
    "\n",
    "sorted_indices = np.argsort(misclassified_scores_NO)[::-1]\n",
    "#sorted_indices\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Text : {misclassified_texts_NO[sorted_indices[i]]}\")\n",
    "    print(f\"Label : {misclassified_labels_NO[sorted_indices[i]]}\")\n",
    "    print(f\"True Label : {misclassified_true_labels_NO[sorted_indices[i]]}\")\n",
    "    print(f\"Score : {misclassified_scores_NO[sorted_indices[i]]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces erreurs mettent en évidence certaines limites de ce modèle dans l'interprétation du langage humain, notamment en matière de contexte, d'argot et de nuances dans l'usage des jurons.\n",
    "\n",
    "Par exemple : \"@user I guess that’s where swamp ass originated\" \n",
    "\n",
    "Cette phrase utilise une expression argotique qui peut être considérée comme vulgaire dans certains contextes, mais ici, elle est probablement utilisée de manière humoristique. Le modèle a mal interprété le contexte."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. (2 points) Extract the top 10 tweets your model is most confident about in the target class (offensive or hateful), the top 10 in the neutral class, and the top 10 your model is most uncertain about. Do you believe the model is doing a great job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open(\"tweets.json\", \"r\") as f:\n",
    "    tweets = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(tweets)\n",
    "\n",
    "predictions = []\n",
    "scores = []\n",
    "for text in df[\"text\"]:\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    _, predicted = torch.max(output.logits, 1)\n",
    "    predictions.append(predicted.detach().cpu().numpy().flatten())\n",
    "    score = torch.nn.functional.softmax(output.logits, dim=1).detach().cpu().numpy()\n",
    "    scores.append(score[0][predicted.item()])\n",
    "\n",
    "df[\"prediction\"] = predictions\n",
    "df[\"score\"] = scores\n",
    "\n",
    "top_10_offensive = df[df[\"prediction\"] == 1].sort_values(\"score\", ascending=False).head(10)\n",
    "top_10_neutral = df[df[\"prediction\"] == 0].sort_values(\"score\", ascending=False).head(10)\n",
    "\n",
    "# Get top 10 uncertain predictions\n",
    "df[\"uncertainty\"] = 1 - df[\"score\"]\n",
    "top_10_uncertain = df.sort_values(\"uncertainty\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2198    don’t you suck his dick or something ? ur fuck...\n",
       "7686    i genuinely feel sick to my stomach and i cann...\n",
       "4042                                You're a little bitch\n",
       "9867                   Bitch you raggedy af phony ass hoe\n",
       "9141                        You're a fucking racist moron\n",
       "3849                     Shut the fuck up you damn monkey\n",
       "8073               its wild how fucking stupid people are\n",
       "1929    Shut the hell up nobody give a shit about your...\n",
       "2206    You're a fucking dumbass that think's he's bad...\n",
       "7800    This dude is a total crybaby man all he does i...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_offensive['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7811                   Thank you beautiful you are too!!🥰\n",
       "8599                                Thank you for this! 💜\n",
       "1109                  Thank you for your supporttt ! 😍❤️✨\n",
       "1416    Oh, that would be great. I will be waiting, th...\n",
       "8684     Aww thank you, Crystal - that means the world. 💗\n",
       "4249           No problem! Thanks for waiting too 🙆🏻‍♀️❤️\n",
       "6506    Aweeee happy 1 year!!! Hope to see you stream ...\n",
       "4719         Awe I am so so glad you are getting this. ❤️\n",
       "7242                                       Thank you!! 😭💕\n",
       "1345    Thanks for your kind words ❤️ our team are all...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_neutral['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5174                             I'm lucky not literate 🙃\n",
       "3490                     THE PAIN IN MY ARM WORTHS SO BAD\n",
       "7104    its crazy to me that people think fictional ch...\n",
       "4359                                 ok I’m gonna cry now\n",
       "2689            someone pinch me i feel like i’m dreaming\n",
       "6390                                      MY PHONES DYING\n",
       "2897    Why didn’t anyone tell me one piece is also sa...\n",
       "6689    It’s just become a case of ‘this doctor said t...\n",
       "1907                      This is just furry and 100 gecs\n",
       "2662                           this is a big brain moment\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_uncertain['text']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut faire les observations suivantes :\n",
    "\n",
    "- Le modèle a les meilleures résultat en terme de tweets offensive dès que les mots clés sont des insultes et le format est une insulte directe dirigée. \n",
    "Plus on est proche de la forme  [sujet] + [verbe] + [insulte] plus le modèle est efficace.\n",
    "\n",
    "- Le modèle a les meilleures résultats en terme de tweets non offensive dès que les mots clés sont positifs et des adjectifs qualitatifs valorisant.\n",
    "\n",
    "- Au niveau des plus neutres, sont des phrases avec le moins possible d'adjectifs qualificatifs.\n",
    "\n",
    "On peut en déduire que le modèle a une prédominance dans la reconnaissance des mots avant le sens des expressions. \n",
    "\n",
    "Cela pourrait avoir pour conséquences de fausser le modèle en utilisant des jurons de façon valorisante ou des adjectifs valorisants de façon insultante. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. Bonus Use SHAP on the provided tweets, or manually written texts, to see if you can find topics on which the model is biased."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour cette question, lorsque l'on utilise SHAP avec la totalité des tweets le kernel crash trop rapidement. Pour un meilleur visuel on va prendre seulement les 500 premiers tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def f(x):\n",
    "    tv = torch.tensor([tokenizer.encode(v, padding='max_length', max_length=512, truncation=True) for v in x])\n",
    "    attention_mask = (tv!=0).type(torch.int64)\n",
    "    outputs = model(tv, attention_mask=attention_mask)[0].detach().cpu().numpy()\n",
    "    scores = softmax(outputs)\n",
    "    return scores\n",
    "\n",
    "explainer = shap.Explainer(f, tokenizer)\n",
    "\n",
    "shap_values = explainer(tweets[:500])\n",
    "\n",
    "shap.plots.text(shap_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'avons pas eut le temps de finir le lancement proprement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5. Bonus Train a naive Bayes model on the data, and compare its results with this model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate data (7 points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. (1 point) Extract about 100 tweets containing at least 20% of your target class (offensive/hateful), from the 10K tweets provided. You can use the pretrained model to help you find tweets in the target class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser le dataframe que l'on a pu récupérer dans la question précédente pour choisir nos tweets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans notre sample d'analyse personnel nous allons mettre des prédictions le moins possible dans les extrêmes pour challenger l'ambiguité d'interprétation.\n",
    "\n",
    "Pour cela nous allons prendre les score entre 0.50 et 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 100 tweets with at least 20% from the target class.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "offensive_tweets = df[(df[\"prediction\"] == 1) & (df[\"score\"] >= 0.50) & (df[\"score\"] <= 0.80)].sample(20)\n",
    "\n",
    "non_offensive_tweets = df[(df[\"prediction\"] == 0) & (df[\"score\"] >= 0.50) & (df[\"score\"] <= 0.80)].sample(80)\n",
    "\n",
    "sampled_tweets = pd.concat([offensive_tweets, non_offensive_tweets])\n",
    "\n",
    "print(f\"Extracted {len(sampled_tweets)} tweets with at least 20% from the target class.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1804                    THE CLEAN ASS FLIP I CANT DO THIS\n",
       "5984    If that is how crimes are gonna be dealt with ...\n",
       "7968    She’s an entire menace to the Djokovic family ...\n",
       "3289                      Gotta learn how to let shit go.\n",
       "6450    Spite fucked me up. Learning to use positive m...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_tweets['text'][:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. (3 points) Altogether, write down an annotation guildeline (which should be at least 2/3 of a page long)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref Annotation_guideline.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. (1 point) Every person in your group is going to annotate these tweets separately. So if you are 3, annotate them 3 times. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'extraire, nous allons mélanger les lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "sampled_tweets = shuffle(sampled_tweets)\n",
    "sample_tweets_text = sampled_tweets['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tweets_text.to_csv('sample_tweets.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les données sont extraites en csv puis sont mise dans un excel pour être analysée (Ref sampled_tweets_annoted.xlsx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. (2 point) Evaluate your inter-annotaor agreement using Fleiss Kappa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('sample_tweets_annoted.xlsx', sheet_name=None)\n",
    "\n",
    "ratings = []\n",
    "for rater, data_ in data.items():\n",
    "    rater_ratings = data_['label'].tolist()\n",
    "    ratings.append(rater_ratings)\n",
    "ratings = np.array(ratings).transpose()\n",
    "print(len(ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le tableau ne contient pas de NaN.\n"
     ]
    }
   ],
   "source": [
    "if np.isnan(ratings).any():\n",
    "    print(\"Le tableau contient un NaN.\")\n",
    "else:\n",
    "    print(\"Le tableau ne contient pas de NaN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fleiss' Kappa score is: 0.8519615099925979\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "import statsmodels.stats.inter_rater as stats\n",
    "\n",
    "\n",
    "raters, _ = stats.aggregate_raters(ratings)\n",
    "kappa_score = fleiss_kappa(raters)\n",
    "\n",
    "print(f\"The Fleiss' Kappa score is: {kappa_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela suggère qu'il y a un haut niveau d'accord entre les évaluateurs dans notre ensemble de données. C'est généralement interprété comme un niveau d'accord solide et fiable.\n",
    "\n",
    "Cependant, on doit se rappeler que bien que ce score suggère un fort accord, il ne garantit pas la justesse ou l'exactitude des annotations. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5. (Bonus) Iterate on your annotation guideline with what you learned. Please send both version in your report."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref Annotation_guideline_2.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6. Evaluate the model your data. Use a majority vote for labels (remove majority \"can't tell\") and compute the precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
